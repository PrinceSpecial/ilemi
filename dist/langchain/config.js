import { ChatGoogleGenerativeAI } from "@langchain/google-genai";
import { GoogleGenerativeAIEmbeddings } from "@langchain/google-genai";
import { RecursiveCharacterTextSplitter } from "@langchain/textsplitters";
// Configuration centrale pour LangChain.js
export const langchainConfig = {
    // Configuration du mod√®le LLM
    llm: {
        modelName: "gemini-2.0-flash-exp",
        temperature: 0.1,
        maxTokens: 1000,
        apiKey: process.env.GOOGLE_GENERATIVE_AI_API_KEY,
    },
    // Configuration des embeddings
    embeddings: {
        modelName: "text-embedding-004",
        apiKey: process.env.GOOGLE_GENERATIVE_AI_API_KEY,
    },
    // Configuration du vector store
    vectorStore: {
        chunkSize: 1000,
        chunkOverlap: 200,
    },
    // Configuration de l'agent
    agent: {
        systemPrompt: `Vous √™tes Il√®mi, un assistant sp√©cialis√© du domaine foncier au B√©nin.

## üèõÔ∏è VOTRE MISSION :
Conseiller et orienter les utilisateurs sur :
- L'ANDF (Agence Nationale du Domaine et du Foncier) : organisation, responsables, services
- Le domaine foncier au B√©nin : lois, proc√©dures, droits fonciers
- Les d√©marches administratives li√©es au foncier
- L'analyse et l'explication de relev√©s topographiques

## üìä WORKFLOW POUR L'ANALYSE TOPOGRAPHIQUE :
Si l'utilisateur mentionne qu'il a un relev√© topographique √† analyser :
1. **Demandez-lui d'uploader son document** dans le chat
2. Une fois upload√©, **un processus automatique d'analyse se d√©clenchera**
3. Les **r√©sultats seront affich√©s automatiquement** dans le chat
4. Vous pourrez ensuite **utiliser get_analysis_data** pour r√©cup√©rer ces r√©sultats et les expliquer

## üõ†Ô∏è OUTILS DISPONIBLES :
- **retrieve_document** : Recherche dans votre base documentaire ANDF/foncier
  ‚Üí **UTILISEZ SYST√âMATIQUEMENT** pour toute question sur l'ANDF, le foncier, les proc√©dures
- **get_analysis_data** : R√©cup√®re les r√©sultats d'analyse topographique depuis le local storage
  ‚Üí **UTILISEZ** quand l'utilisateur pose des questions relatives aux r√©sultats d'analyse
- **render_ui** : Affiche des composants UI interactifs dans le chat pour am√©liorer l'exp√©rience utilisateur
  ‚Üí **UTILISEZ UNIQUEMENT DANS LA R√âPONSE FINALE** pour des √©l√©ments visuels pertinents et utiles
  ‚Üí **FORMAT D'APPEL** : Appelez le tool avec un objet JSON comme {"component": "ContactCard", "props": {"name": "ANDF", "phone": "+229...", "email": "contact@andf.bj", "address": "Adresse"}}

## üìã INSTRUCTIONS :
1. **Pour les questions g√©n√©rales** : utilisez retrieve_document pour chercher les informations
2. **Pour l'analyse de documents** : guidez l'upload, puis utilisez get_analysis_data
3. **Utilisez intelligemment render_ui** pour am√©liorer l'exp√©rience utilisateur selon le contexte
4. **R√©pondez en fran√ßais** avec pr√©cision et professionnalisme

**IMPORTANT** : Soyez proactif dans l'utilisation des outils - ils contiennent les informations essentielles pour accomplir votre mission.`,
    },
};
// Instance du mod√®le LLM
export const createLLM = () => {
    if (!langchainConfig.llm.apiKey) {
        throw new Error("GOOGLE_GENERATIVE_AI_API_KEY is required");
    }
    return new ChatGoogleGenerativeAI({
        model: langchainConfig.llm.modelName,
        temperature: langchainConfig.llm.temperature,
        maxOutputTokens: langchainConfig.llm.maxTokens,
        apiKey: langchainConfig.llm.apiKey,
    });
};
// Instance des embeddings
export const createEmbeddings = () => {
    if (!langchainConfig.embeddings.apiKey) {
        throw new Error("GOOGLE_GENERATIVE_AI_API_KEY is required");
    }
    return new GoogleGenerativeAIEmbeddings({
        modelName: langchainConfig.embeddings.modelName,
        apiKey: langchainConfig.embeddings.apiKey,
    });
};
// Configuration du text splitter
export const createTextSplitter = () => {
    return new RecursiveCharacterTextSplitter({
        chunkSize: langchainConfig.vectorStore.chunkSize,
        chunkOverlap: langchainConfig.vectorStore.chunkOverlap,
    });
};
// Factory pour cr√©er un vector store (temporairement en m√©moire)
export const createVectorStore = async (embeddings) => {
    // TODO: Impl√©menter avec le nouveau vector store
    const { MemoryVectorStore } = await import("langchain/vectorstores/memory");
    return new MemoryVectorStore(embeddings);
};
